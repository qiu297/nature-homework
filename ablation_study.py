import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import jieba
import jieba.posseg as pseg  # å¼•å…¥è¯æ€§æ ‡æ³¨æ¨¡å—
import copy
from collections import Counter
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from tqdm import tqdm

# --- 1. åŸºç¡€é…ç½® ---
IF_CUDA = torch.cuda.is_available()
DEVICE = torch.device("cuda" if IF_CUDA else "cpu")
MAX_LEN = 256
FIXED_BUDGET = 0.20  # å›ºå®šé¢„ç®—ï¼Œæ§åˆ¶å˜é‡
ABLATION_MODES = ['noun', 'verb', 'mixed']  # ä¸‰ç§æ¶ˆèæ¨¡å¼


# --- 2. è¯æ€§æ”»å‡»å™¨ç±» (POS-Aware Attacker) ---
class POSAttacker:
    def __init__(self, model, vocab, cilin_path='cilin.txt'):
        self.model = model
        self.vocab = vocab
        self.syn_dict = {}
        # æ¨¡æ‹Ÿè¯æ—åŠ è½½
        if os.path.exists(cilin_path):
            with open(cilin_path, 'r', encoding='utf-8') as f:
                for line in f:
                    p = line.strip().split(' ')
                    if len(p) > 2 and p[0][-1] == '=':
                        for w in p[1:]: self.syn_dict[w] = [x for x in p[1:] if x != w]

    def get_prob(self, text):
        # é’ˆå¯¹LSTMæ¨¡å‹çš„é¢„æµ‹é€»è¾‘
        tokens = [self.vocab.get(w, 0) for w in jieba.lcut(text)]
        tokens = (tokens[:MAX_LEN] + [0] * MAX_LEN)[:MAX_LEN]
        input_tensor = torch.tensor([tokens]).to(DEVICE)
        with torch.no_grad():
            out = self.model(input_tensor)
            return torch.softmax(out, dim=1).cpu().numpy()[0]

    def _check_pos(self, word, mode):
        """
        æ ¸å¿ƒè¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥è¯æ€§æ˜¯å¦ç¬¦åˆå½“å‰æ¶ˆèæ¨¡å¼
        """
        # ä½¿ç”¨ jieba.posseg è·å–å•ä¸ªè¯çš„è¯æ€§
        # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ•ˆç‡é€šå¸¸æ˜¯å¯¹æ•´å¥åˆ†è¯ï¼Œä¸ºäº†æ¼”ç¤ºæ¸…æ™°å†™æˆå•è¯æ£€æŸ¥
        flags = [flag for _, flag in pseg.cut(word)]
        if not flags: return False
        flag = flags[0]

        if mode == 'noun':
            return flag.startswith('n')  # n, nr, ns, nt...
        elif mode == 'verb':
            return flag.startswith('v')  # v, vn, vd...
        elif mode == 'mixed':
            return True  # æ··åˆæ¨¡å¼ä¸é™åˆ¶
        return False

    def attack(self, text, label, mode='mixed'):
        """
        params:
            mode: 'noun' (ä»…åè¯), 'verb' (ä»…åŠ¨è¯), 'mixed' (æ··åˆ)
        """
        # ä½¿ç”¨ pseg è¿›è¡Œåˆ†è¯å’Œè¯æ€§æ ‡æ³¨
        words_flags = list(pseg.cut(text))
        words = [w for w, f in words_flags]
        flags = [f for w, f in words_flags]

        current_words = copy.deepcopy(words)
        orig_prob = self.get_prob(text)[label]

        max_changes = max(1, int(len(words) * FIXED_BUDGET))

        # 1. ç­›é€‰ç¬¦åˆè¯æ€§è¦æ±‚çš„å€™é€‰è¯
        candidates_idx = []
        for i, (w, flag) in enumerate(zip(words, flags)):
            # å…³é”®åˆ¤å®šï¼šæ ¹æ® mode å†³å®šæ˜¯å¦å…è®¸ä¿®æ”¹è¯¥è¯
            is_target_pos = False
            if mode == 'noun' and flag.startswith('n'):
                is_target_pos = True
            elif mode == 'verb' and flag.startswith('v'):
                is_target_pos = True
            elif mode == 'mixed':
                is_target_pos = True

            if is_target_pos and w in self.syn_dict:
                candidates_idx.append(i)

        # 2. è®¡ç®—é‡è¦æ€§ (åªè®¡ç®—ç­›é€‰å‡ºçš„è¯)
        importance = []
        for i in candidates_idx:
            tmp = words[:i] + words[i + 1:]
            importance.append((i, orig_prob - self.get_prob("".join(tmp))[label]))

        importance.sort(key=lambda x: x[1], reverse=True)

        # 3. æ›¿æ¢é€»è¾‘
        count = 0
        changed_log = []
        for idx, _ in importance:
            if count >= max_changes: break

            old_w = current_words[idx]
            best_syn = old_w
            min_p = 1.0

            for syn in self.syn_dict[old_w]:
                current_words[idx] = syn
                new_prob = self.get_prob("".join(current_words))

                # æ”»å‡»æˆåŠŸåˆ¤å®š
                if np.argmax(new_prob) != label:
                    return "".join(current_words), True, mode

                if new_prob[label] < min_p:
                    min_p = new_prob[label]
                    best_syn = syn

            if best_syn != old_w:
                current_words[idx] = best_syn
                count += 1
                changed_log.append(f"{old_w}({flags[idx]})->{best_syn}")

        return "".join(current_words), False, mode


# --- 3. æ¨¡å‹å®šä¹‰ (éœ€ä¸LSTMä¸€è‡´) ---
class LSTMClassifier(nn.Module):
    def __init__(self, vocab_size):
        super(LSTMClassifier, self).__init__()
        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=0)
        self.lstm = nn.LSTM(128, 128, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(128 * 2, 2)

    def forward(self, x):
        embedded = self.embedding(x)
        _, (h, _) = self.lstm(embedded)
        return self.fc(torch.cat((h[-2, :, :], h[-1, :, :]), dim=1))


# --- 4. æ¶ˆèå®éªŒä¸»ç¨‹åº ---
def run_ablation_study():
    print("\n" + "=" * 60)
    print(f"ğŸ§ª å¯åŠ¨ 4.4.3 æ”»å‡»ç­–ç•¥æ¶ˆèå®éªŒ (Target Model: LSTM)")
    print(f"ğŸ¯ æ”»å‡»é¢„ç®—: {FIXED_BUDGET * 100}% | å¯¹æ¯”æ¨¡å¼: {ABLATION_MODES}")
    print("=" * 60)

    # æ•°æ®ä¸è¯è¡¨æ„å»º
    df = pd.read_csv("test_data.csv").sample(100, random_state=42)  # ä»…ç”¨æµ‹è¯•é›†æ¼”ç¤º
    df['label'] = df['is_fraud'].apply(lambda x: 1 if str(x).lower() in ['1', 'true'] else 0)

    # æ¨¡æ‹Ÿè¯è¡¨ (å®é™…åº”ä» train_data æ„å»º)
    all_tokens = []
    for t in df['specific_dialogue_content']: all_tokens.extend(jieba.lcut(t))
    vocab = {w: i + 1 for i, (w, _) in enumerate(Counter(all_tokens).most_common(10000))}

    # åˆå§‹åŒ–æ¨¡å‹ (ä»…ä»¥æ­¤ä¸ºä¾‹ï¼Œå®é™…éœ€ load_state_dict)
    model = LSTMClassifier(len(vocab) + 2).to(DEVICE)
    model.eval()

    attacker = POSAttacker(model, vocab)

    final_results = []

    # éå†ä¸‰ç§æ¨¡å¼ï¼šä»…åè¯ã€ä»…åŠ¨è¯ã€æ··åˆ
    for mode in ABLATION_MODES:
        print(f"\nâš™ï¸  æ­£åœ¨æ‰§è¡Œæ¨¡å¼: [{mode.upper()}] ...")
        y_true, y_att = [], []

        for _, row in tqdm(df.iterrows(), total=len(df)):
            txt, lab = row['specific_dialogue_content'], row['label']
            p_o = np.argmax(attacker.get_prob(txt))
            y_true.append(lab)

            if p_o == lab and lab == 1:
                # ä¼ å…¥ mode å‚æ•°è¿›è¡Œå®šå‘æ”»å‡»
                adv, success, _ = attacker.attack(txt, lab, mode=mode)
                y_att.append(np.argmax(attacker.get_prob(adv)))
            else:
                y_att.append(p_o)

        # ç»Ÿè®¡å½“å‰æ¨¡å¼ä¸‹çš„æŒ‡æ ‡
        metrics = {
            "Mode": mode,
            "Accuracy": accuracy_score(y_true, y_att),
            "Precision": precision_score(y_true, y_att, zero_division=0),
            "Recall": recall_score(y_true, y_att, zero_division=0)
        }

        # è®¡ç®— Specificity
        tn, fp, fn, tp = confusion_matrix(y_true, y_att).ravel()
        metrics["Specificity"] = tn / (tn + fp) if (tn + fp) > 0 else 0

        final_results.append(metrics)

    # è¾“å‡ºæœ€ç»ˆå¯¹æ¯”è¡¨æ ¼ (å¯¹åº”æ–‡æ¡£ Table 9)
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ¶ˆèå®éªŒæœ€ç»ˆç»“æœæ±‡æ€»")
    print("=" * 60)
    res_df = pd.DataFrame(final_results)
    # è°ƒæ•´åˆ—é¡ºåº
    cols = ["Mode", "Accuracy", "Precision", "Recall", "Specificity"]
    print(res_df[cols].round(4).to_string(index=False))
    res_df.to_csv("ablation_study_results.csv", index=False)


if __name__ == "__main__":
    run_ablation_study()