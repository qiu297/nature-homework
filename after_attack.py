import os
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import jieba
import copy
from collections import Counter
from sklearn.svm import SVC
from tqdm import tqdm
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix

# --- 1. é…ç½®ä¸ç¡¬ä»¶æ£€æµ‹ ---
IF_CUDA = torch.cuda.is_available()
DEVICE = torch.device("cuda" if IF_CUDA else "cpu")
VOCAB_SIZE, MAX_LEN = 15000, 256
ATTACK_BUDGET = 0.20  # 20% ä¿®æ”¹é¢„ç®—


def print_device_info():
    print("=" * 65)
    print(f"ğŸ’» ç¡¬ä»¶æŠ¥å‘Š: {'âœ… GPU åŠ é€Ÿæ¨¡å¼' if IF_CUDA else 'ğŸ¢ CPU æ¨¡å¼'}")
    if IF_CUDA: print(f"ğŸš€ æ˜¾å¡å‹å·: {torch.cuda.get_device_name(0)}")
    print("=" * 65)


# --- 2. æ¨¡å‹ç»“æ„ ---
class LSTMClassifier(nn.Module):
    def __init__(self, vocab_size):
        super(LSTMClassifier, self).__init__()
        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=0)
        self.lstm = nn.LSTM(128, 128, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(128 * 2, 2)

    def forward(self, x):
        embedded = self.embedding(x)
        _, (h, _) = self.lstm(embedded)
        return self.fc(torch.cat((h[-2, :, :], h[-1, :, :]), dim=1))


class CNNClassifier(nn.Module):
    def __init__(self, vocab_size):
        super(CNNClassifier, self).__init__()
        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=0)
        self.convs = nn.ModuleList([nn.Conv1d(128, 100, fs) for fs in [3, 4, 5]])
        self.fc = nn.Linear(300, 2)

    def forward(self, x):
        e = self.embedding(x).permute(0, 2, 1)
        return self.fc(torch.cat([torch.max(torch.relu(conv(e)), dim=2)[0] for conv in self.convs], dim=1))


# --- 3. è¯Šæ–­å¢å¼ºå‹æ”»å‡»ç±» ---
class SynonymAttacker:
    def __init__(self, model, model_type, vocab, tfidf, cilin_path='cilin.txt'):
        self.model = model
        self.model_type = model_type
        self.vocab = vocab
        self.tfidf = tfidf
        self.syn_dict = {}
        if os.path.exists(cilin_path):
            with open(cilin_path, 'r', encoding='utf-8') as f:
                for line in f:
                    p = line.strip().split(' ')
                    if len(p) > 2 and p[0][-1] == '=':
                        for w in p[1:]: self.syn_dict[w] = [x for x in p[1:] if x != w]

    def get_prob(self, text):
        if self.model_type == 'ml':
            return self.model.predict_proba(self.tfidf.transform([text]))[0]
        else:
            max_idx = self.model.embedding.num_embeddings
            tokens = [self.vocab.get(w, 0) for w in jieba.lcut(text)]
            tokens = [t if t < max_idx else 0 for t in tokens]
            tokens = (tokens[:MAX_LEN] + [0] * MAX_LEN)[:MAX_LEN]
            with torch.no_grad():
                out = self.model(torch.LongTensor([tokens]).to(DEVICE))
                return torch.softmax(out, dim=1).cpu().numpy()[0]

    def attack(self, text, label):
        words = jieba.lcut(text)
        current_words = copy.deepcopy(words)
        change_info = []
        importance = []
        orig_prob = self.get_prob(text)[label]
        for i, w in enumerate(words):
            if w in self.syn_dict:
                tmp = words[:i] + words[i + 1:]
                importance.append((i, orig_prob - self.get_prob("".join(tmp))[label]))
        importance.sort(key=lambda x: x[1], reverse=True)
        limit = max(1, int(len(words) * ATTACK_BUDGET))
        count = 0
        for idx, _ in importance:
            if count >= limit: break
            old_w = current_words[idx]
            best_syn, min_p = old_w, self.get_prob("".join(current_words))[label]
            for cand in self.syn_dict[old_w]:
                current_words[idx] = cand
                p = self.get_prob("".join(current_words))[label]
                if p < min_p:
                    min_p, best_syn = p, cand
                if np.argmax(self.get_prob("".join(current_words))) != label:
                    change_info.append(f"{old_w}->{cand}")
                    return "".join(current_words), True, change_info
            if best_syn != old_w:
                change_info.append(f"{old_w}->{best_syn}")
                count += 1
            current_words[idx] = best_syn
        return "".join(current_words), False, change_info


# --- 4. å®éªŒä¸»ç¨‹åº ---
def run_evaluation():
    print_device_info()
    train_df = pd.read_csv("train_data.csv")
    test_df = pd.read_csv("test_data.csv").sample(100)  # é€‰å–100ä¸ªæ ·æœ¬è¿›è¡Œæ”»å‡»è¯„ä¼°

    train_df['label'] = train_df['is_fraud'].apply(lambda x: 1 if str(x).lower() in ['1', 'true', 'fraud'] else 0)
    test_df['label'] = test_df['is_fraud'].apply(lambda x: 1 if str(x).lower() in ['1', 'true', 'fraud'] else 0)

    tfidf = TfidfVectorizer(max_features=5000, tokenizer=jieba.lcut, token_pattern=None).fit(
        train_df['specific_dialogue_content'])
    all_tokens = []
    for t in train_df['specific_dialogue_content']: all_tokens.extend(jieba.lcut(t))
    vocab = {w: i + 1 for i, (w, _) in enumerate(Counter(all_tokens).most_common(VOCAB_SIZE - 1))}

    # åŒ…å« RF åœ¨å†…çš„ 6 ä¸ªæ¨¡å‹é…ç½®
    models_config = [
        ("MNB", MultinomialNB(), 'ml'),
        ("SVM", SVC(kernel='linear', probability=True), 'ml'),
        ("LR", LogisticRegression(), 'ml'),
        ("RF", RandomForestClassifier(), 'ml'),
        ("LSTM", None, 'dl'),
        ("CNN", None, 'dl')
    ]

    all_results = []
    print("\nğŸ” æ­£åœ¨è¿›è¡Œ 20% é¢„ç®—ä¸‹çš„åŒä¹‰è¯æ”¹å†™æ”»å‡»æµ‹è¯•...")

    for name, m_obj, m_type in models_config:
        print(f"è¯„ä¼°è¿›åº¦: [{name}] å¤„ç†ä¸­...")
        if m_type == 'ml':
            m_obj.fit(tfidf.transform(train_df['specific_dialogue_content']), train_df['label'])
            model = m_obj
        else:
            path = f"{name.lower()}_model.pth"
            if not os.path.exists(path):
                print(f"âš ï¸ è·³è¿‡ {name}: æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ {path}")
                continue
            ckpt = torch.load(path, map_location=DEVICE)
            model = LSTMClassifier(ckpt['embedding.weight'].shape[0]) if name == "LSTM" else CNNClassifier(
                ckpt['embedding.weight'].shape[0])
            model.load_state_dict(ckpt)
            model.to(DEVICE).eval()

        attacker = SynonymAttacker(model, m_type, vocab, tfidf)
        y_true, y_att = [], []
        examples = []

        for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=f"  {name} æ”»å‡»æµ‹è¯•"):
            txt, lab = row['specific_dialogue_content'], row['label']
            # è·å–åŸå§‹é¢„æµ‹ç»“æœ
            p_o = np.argmax(attacker.get_prob(txt))
            y_true.append(lab)

            # æ”»å‡»é€»è¾‘ï¼šåªé’ˆå¯¹åŸæœ¬è¯†åˆ«æ­£ç¡®çš„æ­£ç±»ï¼ˆæ¬ºè¯ˆï¼‰æ ·æœ¬å‘èµ·æ”¹å†™
            if p_o == lab and lab == 1:
                adv, success, changes = attacker.attack(txt, lab)
                p_a = np.argmax(attacker.get_prob(adv))
                y_att.append(p_a)
                if success and p_a == 0:
                    examples.append({"old": txt, "new": adv, "changes": changes})
            else:
                y_att.append(p_o)  # å…¶ä»–æ ·æœ¬ä¿æŒåŸæ ·

        # è¯Šæ–­è¾“å‡ºï¼ˆå¸®åŠ©åˆ†æåŸå› ï¼‰
        if examples:
            sample = examples[0]
            print(f"   ğŸ’¡ æ”»å‡»æˆåŠŸå…¸å‹æ›¿æ¢: {', '.join(sample['changes'][:3])}")

        # è®¡ç®—å››ä¸ªæŒ‡æ ‡
        acc = accuracy_score(y_true, y_att)
        pre = precision_score(y_true, y_att, zero_division=0)
        rec = recall_score(y_true, y_att, zero_division=0)
        tn, fp, fn, tp = confusion_matrix(y_true, y_att).ravel()
        spec = tn / (tn + fp) if (tn + fp) > 0 else 0

        all_results.append({
            "Model": name,
            "Acc": acc,
            "Pre": pre,
            "Rec": rec,
            "Spec": spec
        })

    # è¾“å‡ºè¡¨æ ¼ï¼šä»…åŒ…å« After_Attack æ•°æ®
    df_res = pd.DataFrame(all_results).round(4)
    print("\n" + "=" * 80)
    print(f"ğŸ“Š åŒä¹‰è¯æ”¹å†™æ”»å‡»å®éªŒç»“æœ (20% ä¿®æ”¹é¢„ç®—)")
    print("=" * 80)
    print(df_res)
    print("=" * 80)
    df_res.to_csv("after_attack_4metrics_results.csv", index=False)


if __name__ == "__main__":
    run_evaluation()