这份 `README.md` 是根据您提供的实验代码（包含通话数据集与 Spam 数据集的 Baseline 和 Attack 脚本）以及期末大作业的要求定制编写的。它涵盖了项目背景、环境配置、文件结构及运行指南。

---

# 对抗性数据改写在欺诈检测中的鲁棒性评估

本项目为自然语言处理（NLP）期末大作业，旨在通过对抗性语义改写（Adversarial Text Rewriting）技术，评估并分析传统机器学习模型与深度学习模型在欺诈检测场景下的稳健性（Robustness）。

## 1. 项目背景

现有的欺诈识别系统（如垃圾邮件过滤、电信诈骗检测）虽然在标准数据集上表现优异，但往往依赖于特定的关键词统计特征。本项目参考 **TextFooler** 算法，通过同义词替换和语义约束生成对抗样本，验证模型在面对“语义保持、表述不同”的改写攻击时是否存在严重的性能崩塌。

## 2. 环境配置

本项目依赖于 Python 3.8+ 环境，建议使用 GPU 加速深度学习模型的推理。

### 安装依赖

请确保已安装 `requirements.txt` 中的所有包：

```bash
pip install -r requirements.txt

```

### 资源准备

对于 Spam 数据集攻击，代码依赖于 **NLTK WordNet**。首次运行请确保执行：

```python
import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')

```

## 3. 文件结构说明

| 文件名 | 说明 |
| --- | --- |
| `baseline.py` | 通话数据集的基准训练代码，包含 6 种模型（MNB, SVM, LR, RF, LSTM, CNN） |
| `after_attack.py` | 针对通话数据集的对抗改写攻击脚本 |
| `Spam_baseline.py` | Spam 数据集（英文）的基准训练代码 |
| `Spam_afterattack.py` | 针对 Spam 数据集的对抗改写攻击脚本 |
| `requirements.txt` | 项目运行所需的软件依赖列表 |
| `*.pth` | 训练完成后生成的深度学习模型权重文件（运行 Baseline 后产生） |

## 4. 实验流程

### 第一步：训练基准模型 (Baseline)

首先在原始数据集上训练并评估模型性能，确立性能基准：

```bash
python baseline.py       # 执行通话数据基准测试
python Spam_baseline.py  # 执行 Spam 数据基准测试

```

### 第二步：实施对抗攻击 (Attack)

利用训练好的模型权重和 TF-IDF 向量化器，生成对抗样本并观察指标变化：

```bash
python after_attack.py       # 对通话数据发起攻击
python Spam_afterattack.py   # 对 Spam 数据发起攻击

```

## 5. 核心算法原理

本项目采用的攻击算法逻辑如下：

1. **词重要性评估**：通过“删词法”计算每个单词对模型判断欺诈倾向的贡献度。
2. **同义词替换**：在词向量空间或 WordNet 中寻找与关键词语义最接近的候选词。
3. **语义与词性过滤**：确保替换后的文本在词性（POS）和整体语义（USE 相似度）上与原句保持高度一致。
4. **决策绕过**：通过迭代替换，使模型最终将“欺诈”类样本误判为“正常”类。

## 6. 实验结论总结

通过运行本项目，可以观察到：

* **深度学习模型（LSTM/CNN）** 在原始数据上精度极高，但在 20% 预算的攻击下 Recall（召回率）下降最为剧烈。
* **随机森林（RF）** 表现出了一定的特征冗余防御能力，鲁棒性相对较好。
* **Spam 数据集** 由于文本较长，提供了天然的冗余防御，但仍无法抵御针对性的关键词抹除。

---

